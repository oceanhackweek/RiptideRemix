{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef0a421-5973-4755-9ef6-757a802bfa36",
   "metadata": {},
   "source": [
    "# Pull OrcaSound hydrophone data from Amazon Web Service buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d124a5-a263-4338-9042-a9176c8a104d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import os\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "import pandas as pd\n",
    "import ffmpeg\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import paramiko\n",
    "import json\n",
    "import IPython.display as ipd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34228971-bd06-405e-b745-4c67a62c9de4",
   "metadata": {},
   "source": [
    "## Choose your amazon web service bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193f876-5a59-4dda-8506-c9e595f992c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the S3 client with unsigned configuration\n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = 'audio-orcasound-net'\n",
    "prefix_options = ['rpi_bush_point/hls/', \n",
    "                  'rpi_mast_center/hls/', \n",
    "                  'rpi_north_sjc/hls/', \n",
    "                  'rpi_orcasound_lab/hls/', \n",
    "                  'rpi_point_robinson/hls/', \n",
    "                  'rpi_port_townsend/hls/', \n",
    "                  'rpi_sunset_bay/hls/']\n",
    "\n",
    "prefix = 'rpi_sunset_bay/hls/'\n",
    "\n",
    "directories, num_directories = [], []\n",
    "files, buckets = [], []\n",
    "\n",
    "# List objects in the specified bucket and prefix\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')\n",
    "\n",
    "# Print directory (pseudo-folder) names\n",
    "if 'CommonPrefixes' in response:\n",
    "    for prefix_info in response['CommonPrefixes']:\n",
    "        directories.append(prefix_info['Prefix'])\n",
    "        # Get the numeric part of the directory name\n",
    "        num = prefix_info['Prefix'].split('/')[-2]  # Get the last directory name before the trailing '/'\n",
    "        num_directories.append(int(num))\n",
    "\n",
    "# Print file names\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        files.append(obj['Key'])\n",
    "\n",
    "# List all buckets inside selected node\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "operation_parameters = {\n",
    "    'Bucket': bucket_name,\n",
    "    'Prefix': prefix,\n",
    "    'Delimiter': '/'\n",
    "}\n",
    "\n",
    "for page in paginator.paginate(**operation_parameters):\n",
    "    if 'CommonPrefixes' in page:\n",
    "            for prefix_info in page['CommonPrefixes']:\n",
    "                dir_name = prefix_info['Prefix']\n",
    "                dir_number = int(dir_name.split('/')[-2])\n",
    "                buckets.append(dir_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0aa53-e726-4354-8295-bb675d973e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the date and time in pst and returns the bucket that contains that time\n",
    "\n",
    "def choose_bucket(date, dur):\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d_%H.%M.%S')\n",
    "    end_dt = dt + timedelta(seconds=dur)\n",
    "    end_date = end_dt.strftime('%Y-%m-%d_%H.%M.%S')\n",
    "\n",
    "    year, month, day = int(date[0:4]), int(date[5:7]), int(date[8:10])\n",
    "    start_hour, start_min, start_sec = int(date[11:13]), int(date[14:16]), int(date[17:19])\n",
    "    end_hour, end_min, end_sec = int(end_date[11:13]), int(end_date[14:16]), int(end_date[17:19])\n",
    "\n",
    "    # save the input times to datetime objects in PST/PDT\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    start_time = pst.localize(datetime(year, month, day, start_hour, start_min, start_sec))\n",
    "    end_time = pst.localize(datetime(year, month, day, end_hour, end_min, end_sec))\n",
    "    print('Starting time:', start_time, '\\nEnding time:', end_time)\n",
    "\n",
    "    # Identify the bucket based on converted unix start and end times from PST/PDT, uses the max of a list of all buckets below the start time\n",
    "    start_unix_time = int(start_time.timestamp())\n",
    "    end_unix_time = int(end_time.timestamp())\n",
    "    use_bucket = int(max([val for val in buckets if val < start_unix_time]))\n",
    "\n",
    "    # buffers ~20s before and after the calculated time for files to pull within the bucket\n",
    "    start_live = round((start_unix_time - use_bucket)/10)\n",
    "    end_live = round((end_unix_time - use_bucket)/10)\n",
    "    #print(f'Using the bucket {use_bucket} with a live range of .{start_live} to .{end_live}')\n",
    "\n",
    "    return use_bucket, start_time, end_time, start_live, end_live\n",
    "\n",
    "\n",
    "def pull_ts_files(use_bucket, start_time, start_live, end_live):\n",
    "    loc_fol = f'{use_bucket}_{start_time}'\n",
    "    os.makedirs(loc_fol, exist_ok=True)\n",
    "    \n",
    "    metadata = {}\n",
    "\n",
    "    # pulls the live files identified and saves them in a folder named with the bucket and the start time of the chunk\n",
    "    s = start_live\n",
    "    while s <= end_live:\n",
    "        aws_filename = f'live{s}.ts'\n",
    "        s3_key = f'rpi_sunset_bay/hls/{use_bucket}/{aws_filename}'\n",
    "        download_path = os.path.join(loc_fol, aws_filename)\n",
    "        try:\n",
    "            s3_client.download_file(bucket_name, s3_key, download_path)\n",
    "            response = s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "            last_modified = response['LastModified']\n",
    "            metadata[aws_filename] = str(last_modified)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in downloading the audio files from AWS: {e}\")\n",
    "        s += 1\n",
    "\n",
    "    # Save metadata to a JSON file\n",
    "    metadata_file = os.path.join(loc_fol, 'metadata.json')\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    return loc_fol\n",
    "\n",
    "\n",
    "def concate_ts_files(local_folder, chunk_name):\n",
    "    output_file = os.path.join(\"ts\", f\"{chunk_name}.ts\")\n",
    "    with open(output_file, 'wb') as outfile:\n",
    "        ts_files = sorted(glob.glob(os.path.join(local_folder, \"*.ts\")))\n",
    "        for ts_file in ts_files:\n",
    "            with open(ts_file, 'rb') as infile:\n",
    "                outfile.write(infile.read())\n",
    "    shutil.rmtree(local_folder)\n",
    "\n",
    "\n",
    "def convert_ts_to_wav(chunk):\n",
    "    in_ts = f\"ts/{chunk}.ts\"\n",
    "    out_wav = os.path.join(\"wavs\", f\"{chunk}.wav\")\n",
    "    \n",
    "    if not os.path.isfile(in_ts):\n",
    "        print(f\"File not found: {in_ts}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    if os.path.isfile(out_wav):\n",
    "        print(f\"Output file already exists: {out_wav}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        ffmpeg.input(in_ts).output(out_wav, acodec='pcm_s16le', ac=2, ar='44100').run(quiet=True, overwrite_output=True)\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error converting {in_ts}: {e}\")\n",
    "\n",
    "    y, sr = librosa.load(out_wav, sr=None)\n",
    "    print(f\"y is {y} and sr is {sr}\")\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def cleanup_directories(*dir_names):\n",
    "    # Remove all contents and then delete the directory itself\n",
    "    for dir_name in dir_names:\n",
    "        dir_path = Path(dir_name)\n",
    "        if dir_path.exists():\n",
    "            shutil.rmtree(dir_path)\n",
    "            print(f\"Deleted {dir_name} and contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fedd0-a014-42bc-973b-7bfc2adb96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT YOUR DESIRED TIME IN PST/PDT AS LISTED ON ORCASOUND'S ONLINE INTERFACE\n",
    "year, month, day = \"2024\", \"12\", \"14\"\n",
    "start_hour, start_min, start_sec = \"17\", \"20\", \"30\"\n",
    "date = f'{year}-{month}-{day}_{start_hour}.{start_min}.{start_sec}'\n",
    "duration = 30\n",
    "\n",
    "# make a ts and wav folder to save stuff in\n",
    "Path(\"ts\").mkdir(exist_ok=True)\n",
    "Path(\"wavs\").mkdir(exist_ok=True)\n",
    "\n",
    "use_bucket, start_time, end_time, start_live, end_live = choose_bucket(date, duration)\n",
    "local_folder = pull_ts_files(use_bucket, start_time, start_live, end_live)\n",
    "\n",
    "chunk_name = os.path.join(start_time.strftime('%Y-%m-%d_%H.%M.%S') + '_to_' + end_time.strftime('%H.%M.%S'))\n",
    "concate_ts_files(local_folder, chunk_name)\n",
    "wavform = convert_ts_to_wav(chunk_name)\n",
    "cleanup_directories(\"ts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pixi)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
