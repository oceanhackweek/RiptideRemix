{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef0a421-5973-4755-9ef6-757a802bfa36",
   "metadata": {},
   "source": [
    "# Pull OrcaSound hydrophone data from Amazon Web Service buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d124a5-a263-4338-9042-a9176c8a104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import os\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "import pandas as pd\n",
    "import ffmpeg\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import paramiko\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34228971-bd06-405e-b745-4c67a62c9de4",
   "metadata": {},
   "source": [
    "## Choose your amazon web service bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2193f876-5a59-4dda-8506-c9e595f992c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the S3 client with unsigned configuration\n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = 'audio-orcasound-net'\n",
    "prefix = 'rpi_sunset_bay/hls/'\n",
    "directories, num_directories = [], []\n",
    "files, buckets = [], []\n",
    "start_buck = 1728111618\n",
    "\n",
    "# List objects in the specified bucket and prefix\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')\n",
    "\n",
    "# Print directory (pseudo-folder) names\n",
    "if 'CommonPrefixes' in response:\n",
    "    for prefix_info in response['CommonPrefixes']:\n",
    "        directories.append(prefix_info['Prefix'])\n",
    "        # Get the numeric part of the directory name\n",
    "        num = prefix_info['Prefix'].split('/')[-2]  # Get the last directory name before the trailing '/'\n",
    "        num_directories.append(int(num))\n",
    "\n",
    "# Print file names\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        files.append(obj['Key'])\n",
    "\n",
    "# List all bucketsinside rpi_sunset_bay/hls/\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "operation_parameters = {\n",
    "    'Bucket': bucket_name,\n",
    "    'Prefix': prefix,\n",
    "    'Delimiter': '/'\n",
    "}\n",
    "for page in paginator.paginate(**operation_parameters):\n",
    "    if 'CommonPrefixes' in page:\n",
    "            for prefix_info in page['CommonPrefixes']:\n",
    "                dir_name = prefix_info['Prefix']\n",
    "                dir_number = int(dir_name.split('/')[-2])\n",
    "                if dir_number >= start_buck:\n",
    "                    buckets.append(dir_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf0aa53-e726-4354-8295-bb675d973e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the date and time in pst and returns the bucket that contains that time\n",
    "def choose_bucket(date, dur):\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d_%H.%M.%S')\n",
    "    end_dt = dt + timedelta(seconds=dur)\n",
    "    end_date = end_dt.strftime('%Y-%m-%d_%H.%M.%S')\n",
    "\n",
    "    year, month, day = int(date[0:4]), int(date[5:7]), int(date[8:10])\n",
    "    start_hour, start_min, start_sec = int(date[11:13]), int(date[14:16]), int(date[17:19])\n",
    "    end_hour, end_min, end_sec = int(end_date[11:13]), int(end_date[14:16]), int(end_date[17:19])\n",
    "\n",
    "    # save the input times to datetime objects in PST/PDT\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    start_time = pst.localize(datetime(year, month, day, start_hour, start_min, start_sec))\n",
    "    end_time = pst.localize(datetime(year, month, day, end_hour, end_min, end_sec))\n",
    "    print('Starting time:', start_time, '\\nEnding time:', end_time)\n",
    "\n",
    "    # Identify the bucket based on converted unix start and end times from PST/PDT, uses the max of a list of all buckets below the start time\n",
    "    start_unix_time = int(start_time.timestamp())\n",
    "    end_unix_time = int(end_time.timestamp())\n",
    "    use_bucket = int(max([val for val in buckets if val < start_unix_time]))\n",
    "\n",
    "    # buffers ~20s before and after the calculated time for files to pull within the bucket\n",
    "    start_live = round((start_unix_time - use_bucket)/10)\n",
    "    end_live = round((end_unix_time - use_bucket)/10)\n",
    "    print(f'Using the bucket {use_bucket} with a live range of .{start_live} to .{end_live}')\n",
    "\n",
    "    return use_bucket, start_time, end_time, start_live, end_live\n",
    "\n",
    "\n",
    "def pull_ts_files(use_bucket, start_time, start_live, end_live):\n",
    "    loc_fol = f'{use_bucket}_{start_time}'\n",
    "    os.makedirs(loc_fol, exist_ok=True)\n",
    "\n",
    "    metadata = {}\n",
    "\n",
    "    # pulls the live files identified and saves them in a folder named with the bucket and the start time of the chunk\n",
    "    s = start_live\n",
    "    while s <= end_live:\n",
    "        aws_filename = f'live{s}.ts'\n",
    "        s3_key = f'rpi_sunset_bay/hls/{use_bucket}/{aws_filename}'\n",
    "        download_path = os.path.join(loc_fol, aws_filename)\n",
    "        try:\n",
    "            s3_client.download_file(bucket_name, s3_key, download_path)\n",
    "            response = s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "            last_modified = response['LastModified']\n",
    "            metadata[aws_filename] = str(last_modified)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in downloading the audio files from AWS: {e}\")\n",
    "        s += 1\n",
    "\n",
    "    # Save metadata to a JSON file\n",
    "    metadata_file = os.path.join(loc_fol, 'metadata.json')\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    return loc_fol\n",
    "\n",
    "\n",
    "def concate_ts_files(local_folder, chunk_name):\n",
    "    output_file = os.path.join(\"ts\", f\"{chunk_name}.ts\")\n",
    "    with open(output_file, 'wb') as outfile:\n",
    "        ts_files = sorted(glob.glob(os.path.join(local_folder, \"*.ts\")))\n",
    "        for ts_file in ts_files:\n",
    "            with open(ts_file, 'rb') as infile:\n",
    "                outfile.write(infile.read())\n",
    "    shutil.rmtree(local_folder)\n",
    "\n",
    "\n",
    "def convert_ts_to_wav(chunk):\n",
    "    in_ts = f\"ts/{chunk}.ts\"\n",
    "    out_wav = os.path.join(\"wavs\", f\"{chunk}.wav\")\n",
    "\n",
    "    if not os.path.isfile(in_ts):\n",
    "        print(f\"File not found: {in_ts}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    if os.path.isfile(out_wav):\n",
    "        print(f\"Output file already exists: {out_wav}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        ffmpeg.input(in_ts).output(out_wav, acodec='pcm_s16le', ac=2, ar='44100').run(quiet=True, overwrite_output=True)\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error converting {in_ts}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853fedd0-a014-42bc-973b-7bfc2adb96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time: 2024-12-23 17:20:30-08:00 \n",
      "Ending time: 2024-12-23 17:21:00-08:00\n",
      "Using the bucket 1734996713 with a live range of .652 to .655\n"
     ]
    }
   ],
   "source": [
    "# INPUT YOUR DESIRED TIME IN PST/PDT AS LISTED ON ORCASOUND'S ONLINE INTERFACE\n",
    "year, month, day = \"2024\", \"12\", \"23\"\n",
    "start_hour, start_min, start_sec = \"17\", \"20\", \"30\"\n",
    "date = f'{year}-{month}-{day}_{start_hour}.{start_min}.{start_sec}'\n",
    "duration = 30\n",
    "\n",
    "# make a ts and wav folder to save stuff in\n",
    "Path(\"ts\").mkdir(exist_ok=True)\n",
    "Path(\"wavs\").mkdir(exist_ok=True)\n",
    "\n",
    "use_bucket, start_time, end_time, start_live, end_live = choose_bucket(date, duration)\n",
    "local_folder = pull_ts_files(use_bucket, start_time, start_live, end_live)\n",
    "\n",
    "chunk_name = os.path.join(start_time.strftime('%Y-%m-%d_%H.%M.%S') + '_to_' + end_time.strftime('%H.%M.%S'))\n",
    "concate_ts_files(local_folder, chunk_name)\n",
    "convert_ts_to_wav(chunk_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pixi)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
